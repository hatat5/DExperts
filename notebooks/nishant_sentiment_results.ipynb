{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import json\n",
    "import codecs\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentiment_results(models_dict, max_gens=None):\n",
    "    res = {}\n",
    "    for model in tqdm(models_dict):\n",
    "        df = pd.read_json(models_dict[model], lines=True)[:max_gens]\n",
    "        sentiment_labels = df.generations.apply(lambda x: [y['label'] for y in x])\n",
    "        positive_proportion = sentiment_labels.apply(lambda x: np.sum([1 for y in x if y == 'POSITIVE'])/len(x))\n",
    "        res[model] = {\n",
    "            'positive_proportion': positive_proportion.mean()\n",
    "        }\n",
    "        # read automatic evaluation\n",
    "#         with open(Path(os.path.dirname(models_dict[model])) / 'eval_results.txt', 'r') as fo:\n",
    "#             for i, line in enumerate(fo):\n",
    "#                 if i < 3:\n",
    "#                     dist_n = float(line.rstrip().replace(f'dist-{i+1} = ', ''))\n",
    "#                     res[model][f'dist-{i+1}'] = dist_n\n",
    "#                 elif i == 3:\n",
    "#                     ppl = float(line.replace('perplexity = ', ''))\n",
    "#                     res[model]['perplexity'] = ppl\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(neutral_prompts_res, adversarial_prompts_res, key):\n",
    "    \"\"\"\n",
    "    return weighted average of dist-n or perplexity value across neural prompts (5k) and adversarial prompts (2.5k)\n",
    "    \"\"\"\n",
    "    return np.average([neutral_prompts_res[model][key], adversarial_prompts_res[model][key]], weights=[2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results corresponding to the top half of Table 3\n",
    "\n",
    "NEUTRAL_DIR = Path('../generations/sentiment/neutral_prompts/')\n",
    "NEG_DIR = Path('../generations/sentiment/negative_prompts/')\n",
    "\n",
    "models = {\n",
    "#     'GPT-2': {\n",
    "#         'neutral_path': NEUTRAL_DIR / 'gpt2/prompted_gens_gpt2.jsonl',\n",
    "#         'neg_path': NEG_DIR / 'gpt2/prompted_gens_gpt2.jsonl',\n",
    "#     },\n",
    "#     'PPLM': {\n",
    "#         'neutral_path': NEUTRAL_DIR / 'pplm/positive/prompted_gens_pplm.jsonl',\n",
    "#         'neg_path': NEG_DIR / 'pplm/prompted_gens_pplm.jsonl'\n",
    "#     },\n",
    "#     'DAPT': {\n",
    "#         'neutral_path': NEUTRAL_DIR / 'dapt/positive/prompted_gens_gpt2.jsonl',\n",
    "#         'neg_path': NEG_DIR / 'dapt/prompted_gens_gpt2.jsonl',\n",
    "#     },\n",
    "#     'GeDi': {\n",
    "#         'neutral_path': NEUTRAL_DIR / 'gedi/positive/prompted_gens_gedi.jsonl',\n",
    "#         'neg_path': NEG_DIR / 'gedi/prompted_gens_gedi.jsonl'\n",
    "#     },\n",
    "#     'CTRL': {\n",
    "#         'neutral_path': NEUTRAL_DIR / 'ctrl/positive/prompted_gens_ctrl.jsonl',\n",
    "#         'neg_path': NEG_DIR / 'ctrl/prompted_gens_ctrl.jsonl'\n",
    "#     },\n",
    "#     'Expert': {\n",
    "#         'neutral_path': NEUTRAL_DIR / 'expert/positive/prompted_gens_gpt2.jsonl',\n",
    "#         'neg_path': NEG_DIR / 'expert/prompted_gens_gpt2.jsonl',\n",
    "#     },\n",
    "    'DExperts (anti-only)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'large_experts/positive/dexperts_anti_only/prompted_gens_dexperts.jsonl',\n",
    "        'neg_path': NEG_DIR / 'large_experts/positive/dexperts_anti_only/prompted_gens_dexperts.jsonl',\n",
    "    },\n",
    "    'DExperts (large)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'large_experts/positive/dexperts/prompted_gens_dexperts.jsonl',\n",
    "        'neg_path': NEG_DIR / 'large_experts/positive/dexperts/prompted_gens_dexperts.jsonl'\n",
    "    },\n",
    "    'DExperts small experts (anti-only)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'small_experts/positive/dexperts_anti_only/prompted_gens_dexperts.jsonl',\n",
    "        'neg_path': NEG_DIR / 'small_experts/positive/dexperts_anti_only/prompted_gens_dexperts.jsonl'\n",
    "    },\n",
    "    'DExperts small experts': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'small_experts/positive/dexperts/prompted_gens_dexperts.jsonl',\n",
    "        'neg_path': NEG_DIR / 'small_experts/positive/dexperts/prompted_gens_dexperts.jsonl'\n",
    "    },\n",
    "    'Layer 24 (anti-only)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'large_experts/positive/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'neg_path': NEG_DIR / 'large_experts/positive/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "    },\n",
    "    'Layer 24': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'large_experts/positive/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'neg_path': NEG_DIR / 'large_experts/positive/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.78it/s]\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# read sentiment control results\n",
    "neutral_prompts_res = read_sentiment_results({m: p['neutral_path'] for m,p in models.items()})\n",
    "neg_prompts_res = read_sentiment_results({m: p['neg_path'] for m,p in models.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_steering_res = {}\n",
    "assert set(neutral_prompts_res.keys()) == set(neg_prompts_res.keys())\n",
    "for model in neutral_prompts_res.keys():\n",
    "    positive_steering_res[model] = {\n",
    "        'neutral_prompts': neutral_prompts_res[model]['positive_proportion']*100,\n",
    "        'neg_prompts': neg_prompts_res[model]['positive_proportion']*100,\n",
    "        #'dist-1': weighted_average(neutral_prompts_res, neg_prompts_res, 'dist-1'),\n",
    "        #'dist-2': weighted_average(neutral_prompts_res, neg_prompts_res, 'dist-2'),\n",
    "        #'dist-3': weighted_average(neutral_prompts_res, neg_prompts_res, 'dist-3'),\n",
    "        #'perplexity': weighted_average(neutral_prompts_res, neg_prompts_res, 'perplexity'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral_prompts</th>\n",
       "      <th>neg_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DExperts small experts (anti-only)</th>\n",
       "      <td>47.73</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 24 (anti-only)</th>\n",
       "      <td>60.13</td>\n",
       "      <td>9.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts (anti-only)</th>\n",
       "      <td>60.72</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 24</th>\n",
       "      <td>62.61</td>\n",
       "      <td>7.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts (large)</th>\n",
       "      <td>94.17</td>\n",
       "      <td>36.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts small experts</th>\n",
       "      <td>94.69</td>\n",
       "      <td>33.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    neutral_prompts  neg_prompts\n",
       "DExperts small experts (anti-only)            47.73         2.60\n",
       "Layer 24 (anti-only)                          60.13         9.89\n",
       "DExperts (anti-only)                          60.72         4.55\n",
       "Layer 24                                      62.61         7.02\n",
       "DExperts (large)                              94.17        36.59\n",
       "DExperts small experts                        94.69        33.54"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(positive_steering_res).transpose().sort_values(by='neutral_prompts', ascending=True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results corresponding to the bottom  half of Table 3\n",
    "\n",
    "NEUTRAL_DIR = Path('../generations/sentiment/neutral_prompts/')\n",
    "POS_DIR = Path('../generations/sentiment/positive_prompts/')\n",
    "\n",
    "models = {\n",
    "#     'GPT-2': {\n",
    "#         'neutral_path': NEUTRAL_DIR / 'gpt2/prompted_gens_gpt2.jsonl',\n",
    "#         'pos_path': POS_DIR / 'gpt2/prompted_gens_gpt2.jsonl',\n",
    "#     },\n",
    "#     'PPLM': {\n",
    "#         'neutral_path': NEUTRAL_DIR / 'pplm/positive/prompted_gens_pplm.jsonl',\n",
    "#         'pos_path': POS_DIR / 'pplm/prompted_gens_pplm.jsonl'\n",
    "#     },\n",
    "#     'DAPT': {\n",
    "#         'neutral_path': NEUTRAL_DIR / 'dapt/positive/prompted_gens_gpt2.jsonl',\n",
    "#         'pos_path': POS_DIR / 'dapt/prompted_gens_gpt2.jsonl',\n",
    "#     },\n",
    "#     'GeDi': {\n",
    "#         'neutral_path': NEUTRAL_DIR / 'gedi/positive/prompted_gens_gedi.jsonl',\n",
    "#         'pos_path': POS_DIR / 'gedi/prompted_gens_gedi.jsonl'\n",
    "#     },\n",
    "#     'CTRL': {\n",
    "#         'neutral_path': NEUTRAL_DIR / 'ctrl/positive/prompted_gens_ctrl.jsonl',\n",
    "#         'pos_path': POS_DIR / 'ctrl/prompted_gens_ctrl.jsonl'\n",
    "#     },\n",
    "#     'Expert': {\n",
    "#         'neutral_path': NEUTRAL_DIR / 'expert/positive/prompted_gens_gpt2.jsonl',\n",
    "#         'pos_path': POS_DIR / 'expert/prompted_gens_gpt2.jsonl',\n",
    "#     },\n",
    "    'DExperts (anti-only)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_anti_only/prompted_gens_dexperts.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_anti_only/prompted_gens_dexperts.jsonl',\n",
    "    },\n",
    "    'DExperts (large)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts/prompted_gens_dexperts.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts/prompted_gens_dexperts.jsonl'\n",
    "    },\n",
    "    'DExperts small experts (anti-only)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'small_experts/negative/dexperts_anti_only/prompted_gens_dexperts.jsonl',\n",
    "        'pos_path': POS_DIR / 'small_experts/negative/dexperts_anti_only/prompted_gens_dexperts.jsonl'\n",
    "    },\n",
    "    'DExperts small experts': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'small_experts/negative/dexperts/prompted_gens_dexperts.jsonl',\n",
    "        'pos_path': POS_DIR / 'small_experts/negative/dexperts/prompted_gens_dexperts.jsonl'\n",
    "    },\n",
    "    'Layer 24 (anti-only)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "    },\n",
    "    'Layer 24': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.95it/s]\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# read sentiment control results\n",
    "neutral_prompts_res = read_sentiment_results({m: p['neutral_path'] for m,p in models.items()})\n",
    "pos_prompts_res = read_sentiment_results({m: p['pos_path'] for m,p in models.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_steering_res = {}\n",
    "assert set(neutral_prompts_res.keys()) == set(pos_prompts_res.keys())\n",
    "for model in neutral_prompts_res.keys():\n",
    "    negative_steering_res[model] = {\n",
    "        'neutral_prompts': neutral_prompts_res[model]['positive_proportion']*100,\n",
    "        'pos_prompts': pos_prompts_res[model]['positive_proportion']*100,\n",
    "#         'dist-1': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-1'),\n",
    "#         'dist-2': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-2'),\n",
    "#         'dist-3': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-3'),\n",
    "#         'perplexity': weighted_average(neutral_prompts_res, pos_prompts_res, 'perplexity'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral_prompts</th>\n",
       "      <th>pos_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer 24 (anti-only)</th>\n",
       "      <td>42.61</td>\n",
       "      <td>91.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 24</th>\n",
       "      <td>36.19</td>\n",
       "      <td>90.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts (anti-only)</th>\n",
       "      <td>30.61</td>\n",
       "      <td>92.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts small experts (anti-only)</th>\n",
       "      <td>25.38</td>\n",
       "      <td>90.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts small experts</th>\n",
       "      <td>4.09</td>\n",
       "      <td>46.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts (large)</th>\n",
       "      <td>3.39</td>\n",
       "      <td>33.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    neutral_prompts  pos_prompts\n",
       "Layer 24 (anti-only)                          42.61        91.05\n",
       "Layer 24                                      36.19        90.71\n",
       "DExperts (anti-only)                          30.61        92.29\n",
       "DExperts small experts (anti-only)            25.38        90.93\n",
       "DExperts small experts                         4.09        46.55\n",
       "DExperts (large)                               3.39        33.95"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(negative_steering_res).transpose().sort_values(by='neutral_prompts', ascending=False).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.26it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  6.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# results corresponding to the bottom  half of Table 3\n",
    "\n",
    "NEUTRAL_DIR = Path('../generations/sentiment/neutral_prompts/')\n",
    "POS_DIR = Path('../generations/sentiment/positive_prompts/')\n",
    "\n",
    "models = {\n",
    "    'Layer 24 (anti-only)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "    },\n",
    "    'Layer 24': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "    },\n",
    "    'Layer 24 combine at logit': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert/combine_at_logit/prompted_gens_dexperts.jsonl',\n",
    "    }\n",
    "}\n",
    "\n",
    "neutral_prompts_res = read_sentiment_results({m: p['neutral_path'] for m,p in models.items()})\n",
    "pos_prompts_res = read_sentiment_results({m: p['pos_path'] for m,p in models.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral_prompts</th>\n",
       "      <th>pos_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer 24 (anti-only)</th>\n",
       "      <td>42.61</td>\n",
       "      <td>91.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 24</th>\n",
       "      <td>36.19</td>\n",
       "      <td>90.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 24 combine at logit</th>\n",
       "      <td>36.19</td>\n",
       "      <td>91.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           neutral_prompts  pos_prompts\n",
       "Layer 24 (anti-only)                 42.61        91.05\n",
       "Layer 24                             36.19        90.71\n",
       "Layer 24 combine at logit            36.19        91.46"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_steering_res = {}\n",
    "assert set(neutral_prompts_res.keys()) == set(pos_prompts_res.keys())\n",
    "for model in neutral_prompts_res.keys():\n",
    "    negative_steering_res[model] = {\n",
    "        'neutral_prompts': neutral_prompts_res[model]['positive_proportion']*100,\n",
    "        'pos_prompts': pos_prompts_res[model]['positive_proportion']*100,\n",
    "#         'dist-1': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-1'),\n",
    "#         'dist-2': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-2'),\n",
    "#         'dist-3': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-3'),\n",
    "#         'perplexity': weighted_average(neutral_prompts_res, pos_prompts_res, 'perplexity'),\n",
    "    }\n",
    "pd.DataFrame(negative_steering_res).transpose().sort_values(by='neutral_prompts', ascending=False).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Alpha experiment, I think fluency is really bad for high alphas and make less logical sense on viewing some of the generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  5.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_0.5</th>\n",
       "      <td>94.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_1.0</th>\n",
       "      <td>93.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_1.5</th>\n",
       "      <td>93.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_2.0</th>\n",
       "      <td>92.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_2.5</th>\n",
       "      <td>91.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_3.0</th>\n",
       "      <td>91.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_3.2</th>\n",
       "      <td>90.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_3.5</th>\n",
       "      <td>90.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_4.0</th>\n",
       "      <td>89.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_5.0</th>\n",
       "      <td>87.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_10.0</th>\n",
       "      <td>77.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_20.0</th>\n",
       "      <td>61.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_24_alpha_30.0</th>\n",
       "      <td>48.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pos_prompts\n",
       "Layer_24_alpha_0.5         94.64\n",
       "Layer_24_alpha_1.0         93.97\n",
       "Layer_24_alpha_1.5         93.32\n",
       "Layer_24_alpha_2.0         92.59\n",
       "Layer_24_alpha_2.5         91.89\n",
       "Layer_24_alpha_3.0         91.09\n",
       "Layer_24_alpha_3.2         90.71\n",
       "Layer_24_alpha_3.5         90.25\n",
       "Layer_24_alpha_4.0         89.40\n",
       "Layer_24_alpha_5.0         87.35\n",
       "Layer_24_alpha_10.0        77.67\n",
       "Layer_24_alpha_20.0        61.13\n",
       "Layer_24_alpha_30.0        48.11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results corresponding to the bottom  half of Table 3\n",
    "\n",
    "POS_DIR = Path('../generations/sentiment/positive_prompts/')\n",
    "\n",
    "models = {}\n",
    "for alpha in [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.2, 3.5, 4.0, 5.0, 10.0, 20.0, 30.0]:\n",
    "    models[f'Layer_24_alpha_{alpha}'] = {\n",
    "        'pos_path': POS_DIR / f'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_{alpha}/layer_24_freeze_emb_lm_head_with_expert/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "    }\n",
    "\n",
    "pos_prompts_res = read_sentiment_results({m: p['pos_path'] for m,p in models.items()})\n",
    "negative_steering_res = {}\n",
    "#assert set(neutral_prompts_res.keys()) == set(pos_prompts_res.keys())\n",
    "for model in pos_prompts_res.keys():\n",
    "    negative_steering_res[model] = {\n",
    "        #'neutral_prompts': neutral_prompts_res[model]['positive_proportion']*100,\n",
    "        'pos_prompts': pos_prompts_res[model]['positive_proportion']*100,\n",
    "#         'dist-1': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-1'),\n",
    "#         'dist-2': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-2'),\n",
    "#         'dist-3': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-3'),\n",
    "#         'perplexity': weighted_average(neutral_prompts_res, pos_prompts_res, 'perplexity'),\n",
    "    }\n",
    "pd.DataFrame(negative_steering_res).transpose().sort_values(by='pos_prompts', ascending=False).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "def return_perplexity_of_sentiment_model(models_dict: Dict[str, str]):\n",
    "    res = {}\n",
    "    for model in tqdm(models_dict):\n",
    "        path_to_model = models_dict[model]\n",
    "        if path_to_model == 'None':\n",
    "            res[model] = {'ppl': -1}\n",
    "        else:\n",
    "            with open(os.path.join(path_to_model, 'eval_results_lm.txt')) as f:\n",
    "                for line in f:\n",
    "                    res[model] = {'ppl': float(line.split(' = ')[1])}\n",
    "                    break\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.27it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 16690.43it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 24892.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_prompts</th>\n",
       "      <th>antiexpert_ppl</th>\n",
       "      <th>expert_ppl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DExperts (anti-only)</th>\n",
       "      <td>92.29</td>\n",
       "      <td>18.81</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 24 (anti-only) 3 epochs</th>\n",
       "      <td>91.05</td>\n",
       "      <td>42.09</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts small experts (anti-only)</th>\n",
       "      <td>90.93</td>\n",
       "      <td>40.04</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 24 3 epochs</th>\n",
       "      <td>90.71</td>\n",
       "      <td>42.09</td>\n",
       "      <td>43.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 24 100 epochs</th>\n",
       "      <td>68.21</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 24 50 epochs</th>\n",
       "      <td>64.32</td>\n",
       "      <td>18.01</td>\n",
       "      <td>17.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 24 (anti-only) 100 epochs</th>\n",
       "      <td>56.00</td>\n",
       "      <td>7.69</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts small experts</th>\n",
       "      <td>46.55</td>\n",
       "      <td>40.04</td>\n",
       "      <td>41.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 24 (anti-only) 50 epochs</th>\n",
       "      <td>40.44</td>\n",
       "      <td>18.01</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts (large)</th>\n",
       "      <td>33.95</td>\n",
       "      <td>18.81</td>\n",
       "      <td>18.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    pos_prompts  antiexpert_ppl  expert_ppl\n",
       "DExperts (anti-only)                      92.29           18.81       -1.00\n",
       "Layer 24 (anti-only) 3 epochs             91.05           42.09       -1.00\n",
       "DExperts small experts (anti-only)        90.93           40.04       -1.00\n",
       "Layer 24 3 epochs                         90.71           42.09       43.80\n",
       "Layer 24 100 epochs                       68.21            7.69        7.20\n",
       "Layer 24 50 epochs                        64.32           18.01       17.93\n",
       "Layer 24 (anti-only) 100 epochs           56.00            7.69       -1.00\n",
       "DExperts small experts                    46.55           40.04       41.09\n",
       "Layer 24 (anti-only) 50 epochs            40.44           18.01       -1.00\n",
       "DExperts (large)                          33.95           18.81       18.58"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Different Language Model experiments\n",
    "\n",
    "# results corresponding to the bottom  half of Table 3\n",
    "\n",
    "POS_DIR = Path('../generations/sentiment/positive_prompts/')\n",
    "model_dir = '../models/experts/sentiment/'\n",
    "source_sentiment = 'positive'\n",
    "target_sentiment = 'negative'\n",
    "\n",
    "models = {\n",
    "    'DExperts (anti-only)': {\n",
    "        #'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_anti_only/prompted_gens_dexperts.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_anti_only/prompted_gens_dexperts.jsonl',\n",
    "        'antiexpert_ppl_path': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}\",\n",
    "        'expert_ppl_path': 'None',\n",
    "    },\n",
    "    'DExperts (large)': {\n",
    "        #'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts/prompted_gens_dexperts.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts/prompted_gens_dexperts.jsonl',\n",
    "        'antiexpert_ppl_path': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}\",\n",
    "        'expert_ppl_path': f\"{model_dir}/large/finetuned_gpt2_{target_sentiment}\",\n",
    "    },\n",
    "    'DExperts small experts (anti-only)': {\n",
    "        #'neutral_path': NEUTRAL_DIR / 'small_experts/negative/dexperts_anti_only/prompted_gens_dexperts.jsonl',\n",
    "        'pos_path': POS_DIR / 'small_experts/negative/dexperts_anti_only/prompted_gens_dexperts.jsonl',\n",
    "        'antiexpert_ppl_path': f\"{model_dir}/small/finetuned_gpt2_{source_sentiment}\",\n",
    "        'expert_ppl_path': 'None',\n",
    "    },\n",
    "    'DExperts small experts': {\n",
    "        #'neutral_path': NEUTRAL_DIR / 'small_experts/negative/dexperts/prompted_gens_dexperts.jsonl',\n",
    "        'pos_path': POS_DIR / 'small_experts/negative/dexperts/prompted_gens_dexperts.jsonl',\n",
    "        'antiexpert_ppl_path': f\"{model_dir}/small/finetuned_gpt2_{source_sentiment}\",\n",
    "        'expert_ppl_path': f\"{model_dir}/small/finetuned_gpt2_{target_sentiment}\",\n",
    "    },\n",
    "    'Layer 24 (anti-only) 3 epochs': {\n",
    "        #'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'antiexpert_ppl_path': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}_experimental_freeze_emb_and_lmhead_layers24\",\n",
    "        'expert_ppl_path': 'None',\n",
    "    },\n",
    "    'Layer 24 3 epochs': {\n",
    "        #'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'antiexpert_ppl_path': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}_experimental_freeze_emb_and_lmhead_layers24\",\n",
    "        'expert_ppl_path': f\"{model_dir}/large/finetuned_gpt2_{target_sentiment}_experimental_freeze_emb_and_lmhead_layers24\",\n",
    "    },\n",
    "    'Layer 24 (anti-only) 50 epochs': {\n",
    "        #'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_epochs50/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'antiexpert_ppl_path': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}_experimental_freeze_emb_and_lmhead_layers24_50\",\n",
    "        'expert_ppl_path': 'None',\n",
    "    },\n",
    "    'Layer 24 50 epochs': {\n",
    "        #'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert_epochs50/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'antiexpert_ppl_path': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}_experimental_freeze_emb_and_lmhead_layers24_50\",\n",
    "        'expert_ppl_path': f\"{model_dir}/large/finetuned_gpt2_{target_sentiment}_experimental_freeze_emb_and_lmhead_layers24_50\",\n",
    "    },\n",
    "    'Layer 24 (anti-only) 100 epochs': {\n",
    "        #'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_epochs100/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'antiexpert_ppl_path': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}_experimental_freeze_emb_and_lmhead_layers24_100\",\n",
    "        'expert_ppl_path': 'None',\n",
    "    },\n",
    "    'Layer 24 100 epochs': {\n",
    "        #'neutral_path': NEUTRAL_DIR / 'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'pos_path': POS_DIR / 'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_24_freeze_emb_lm_head_with_expert_epochs100/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'antiexpert_ppl_path': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}_experimental_freeze_emb_and_lmhead_layers24_100\",\n",
    "        'expert_ppl_path': f\"{model_dir}/large/finetuned_gpt2_{target_sentiment}_experimental_freeze_emb_and_lmhead_layers24_100\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# read sentiment control results\n",
    "pos_prompts_res = read_sentiment_results({m: p['pos_path'] for m,p in models.items()})\n",
    "antiexpert_ppl_res = return_perplexity_of_sentiment_model({m: p['antiexpert_ppl_path'] for m,p in models.items()})\n",
    "expert_ppl_res = return_perplexity_of_sentiment_model({m: p['expert_ppl_path'] for m,p in models.items()})\n",
    "\n",
    "negative_steering_res = {}\n",
    "for model in pos_prompts_res.keys():\n",
    "    negative_steering_res[model] = {\n",
    "        'pos_prompts': pos_prompts_res[model]['positive_proportion']*100,\n",
    "        'antiexpert_ppl': antiexpert_ppl_res[model]['ppl'],\n",
    "        'expert_ppl': expert_ppl_res[model]['ppl'],\n",
    "    }\n",
    "    \n",
    "pd.DataFrame(negative_steering_res).transpose().sort_values(by='pos_prompts', ascending=False).round(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ppl': 7.69039240771082}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos -> neg\n",
    "model_dir = '../models/experts/sentiment/'\n",
    "source_sentiment = 'positive'\n",
    "target_sentiment = 'negative'\n",
    "model_path_to_expert_ppls = {\n",
    "    'DExperts (anti-only)': 'None'#f\"{model_dir}/large/finetuned_gpt2_{target_sentiment}\",\n",
    "    'Layer 24 (anti-only) 3 epochs': 'None'#f\"{model_dir}/large/finetuned_gpt2_{target_sentiment}_experimental_freeze_emb_and_lmhead_layers24\",\n",
    "    'DExperts small experts (anti-only)': 'None'#f\"{model_dir}/small/finetuned_gpt2_{target_sentiment}\",\n",
    "    'Layer 24 3 epochs': f\"{model_dir}/large/finetuned_gpt2_{target_sentiment}_experimental_freeze_emb_and_lmhead_layers24\",\n",
    "    'Layer 24 100 epochs': f\"{model_dir}/large/finetuned_gpt2_{target_sentiment}_experimental_freeze_emb_and_lmhead_layers24_50\",\n",
    "    'Layer 24 50 epochs': f\"{model_dir}/large/finetuned_gpt2_{target_sentiment}_experimental_freeze_emb_and_lmhead_layers24_100\",\n",
    "    'Layer 24 (anti-only) 100 epochs': 'None'#f\"{model_dir}/large/finetuned_gpt2_{target_sentiment}_experimental_freeze_emb_and_lmhead_layers24_100\",\n",
    "    'DExperts small experts': f\"{model_dir}/small/finetuned_gpt2_{target_sentiment}\",\n",
    "    'Layer 24 (anti-only) 50 epochs': 'None',#f\"{model_dir}/large/finetuned_gpt2_{target_sentiment}_experimental_freeze_emb_and_lmhead_layers24_50\",\n",
    "    'DExperts (large)': f\"{model_dir}/large/finetuned_gpt2_{target_sentiment}\",\n",
    "}\n",
    "\n",
    "model_path_to_antiexpert_ppls = {\n",
    "    'DExperts (anti-only)': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}\",\n",
    "    'Layer 24 (anti-only) 3 epochs': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}_experimental_freeze_emb_and_lmhead_layers24\",\n",
    "    'DExperts small experts (anti-only)': f\"{model_dir}/small/finetuned_gpt2_{source_sentiment}\",\n",
    "    'Layer 24 3 epochs': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}_experimental_freeze_emb_and_lmhead_layers24\",\n",
    "    'Layer 24 100 epochs': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}_experimental_freeze_emb_and_lmhead_layers24_50\",\n",
    "    'Layer 24 50 epochs': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}_experimental_freeze_emb_and_lmhead_layers24_100\",\n",
    "    'Layer 24 (anti-only) 100 epochs': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}_experimental_freeze_emb_and_lmhead_layers24_100\",\n",
    "    'DExperts small experts': f\"{model_dir}/small/finetuned_gpt2_{source_sentiment}\",\n",
    "    'Layer 24 (anti-only) 50 epochs': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}_experimental_freeze_emb_and_lmhead_layers24_50\",\n",
    "    'DExperts (large)': f\"{model_dir}/large/finetuned_gpt2_{source_sentiment}\",\n",
    "}\n",
    "\n",
    "pos_prompts_expert_ppl_res = return_perplexity_of_sentiment_model({m: p['pos_path'] for m,p in models.items()})\n",
    "\n",
    "negative_steering_res = {}\n",
    "for model in pos_prompts_res.keys():\n",
    "    negative_steering_res[model] = {\n",
    "        'pos_prompts': pos_prompts_res[model]['positive_proportion']*100,\n",
    "    }\n",
    "    \n",
    "pd.DataFrame(negative_steering_res).transpose().sort_values(by='pos_prompts', ascending=False).round(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 4554.08it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 32362.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive_ppl</th>\n",
       "      <th>negative_ppl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPT2 large</th>\n",
       "      <td>31.35</td>\n",
       "      <td>30.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT2 small</th>\n",
       "      <td>42.89</td>\n",
       "      <td>43.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer0</th>\n",
       "      <td>34.50</td>\n",
       "      <td>33.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1</th>\n",
       "      <td>33.73</td>\n",
       "      <td>32.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer2</th>\n",
       "      <td>33.62</td>\n",
       "      <td>32.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer3</th>\n",
       "      <td>33.65</td>\n",
       "      <td>32.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer4</th>\n",
       "      <td>34.10</td>\n",
       "      <td>33.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer5</th>\n",
       "      <td>33.85</td>\n",
       "      <td>33.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer6</th>\n",
       "      <td>33.72</td>\n",
       "      <td>32.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer7</th>\n",
       "      <td>33.66</td>\n",
       "      <td>33.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer8</th>\n",
       "      <td>34.07</td>\n",
       "      <td>33.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer9</th>\n",
       "      <td>34.05</td>\n",
       "      <td>33.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer10</th>\n",
       "      <td>33.93</td>\n",
       "      <td>33.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer11</th>\n",
       "      <td>34.19</td>\n",
       "      <td>33.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer12</th>\n",
       "      <td>34.23</td>\n",
       "      <td>33.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer13</th>\n",
       "      <td>34.24</td>\n",
       "      <td>33.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer14</th>\n",
       "      <td>34.33</td>\n",
       "      <td>33.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer15</th>\n",
       "      <td>34.63</td>\n",
       "      <td>33.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer16</th>\n",
       "      <td>34.64</td>\n",
       "      <td>33.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer17</th>\n",
       "      <td>34.60</td>\n",
       "      <td>33.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer18</th>\n",
       "      <td>34.54</td>\n",
       "      <td>33.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer19</th>\n",
       "      <td>34.62</td>\n",
       "      <td>34.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer20</th>\n",
       "      <td>34.48</td>\n",
       "      <td>33.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer21</th>\n",
       "      <td>34.36</td>\n",
       "      <td>33.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer22</th>\n",
       "      <td>34.61</td>\n",
       "      <td>34.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer23</th>\n",
       "      <td>34.77</td>\n",
       "      <td>34.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer24</th>\n",
       "      <td>34.82</td>\n",
       "      <td>34.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer25</th>\n",
       "      <td>35.25</td>\n",
       "      <td>34.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer26</th>\n",
       "      <td>35.21</td>\n",
       "      <td>35.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer27</th>\n",
       "      <td>35.15</td>\n",
       "      <td>35.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer28</th>\n",
       "      <td>35.74</td>\n",
       "      <td>35.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer29</th>\n",
       "      <td>36.21</td>\n",
       "      <td>35.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer30</th>\n",
       "      <td>36.21</td>\n",
       "      <td>36.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer31</th>\n",
       "      <td>36.27</td>\n",
       "      <td>36.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer32</th>\n",
       "      <td>36.71</td>\n",
       "      <td>36.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer33</th>\n",
       "      <td>37.00</td>\n",
       "      <td>37.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer34</th>\n",
       "      <td>37.28</td>\n",
       "      <td>37.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer35</th>\n",
       "      <td>37.67</td>\n",
       "      <td>37.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive_ppl  negative_ppl\n",
       "GPT2 large         31.35         30.51\n",
       "GPT2 small         42.89         43.15\n",
       "layer0             34.50         33.45\n",
       "layer1             33.73         32.80\n",
       "layer2             33.62         32.81\n",
       "layer3             33.65         32.94\n",
       "layer4             34.10         33.36\n",
       "layer5             33.85         33.04\n",
       "layer6             33.72         32.96\n",
       "layer7             33.66         33.09\n",
       "layer8             34.07         33.48\n",
       "layer9             34.05         33.28\n",
       "layer10            33.93         33.44\n",
       "layer11            34.19         33.65\n",
       "layer12            34.23         33.93\n",
       "layer13            34.24         33.69\n",
       "layer14            34.33         33.80\n",
       "layer15            34.63         33.74\n",
       "layer16            34.64         33.97\n",
       "layer17            34.60         33.96\n",
       "layer18            34.54         33.96\n",
       "layer19            34.62         34.10\n",
       "layer20            34.48         33.99\n",
       "layer21            34.36         33.64\n",
       "layer22            34.61         34.14\n",
       "layer23            34.77         34.37\n",
       "layer24            34.82         34.52\n",
       "layer25            35.25         34.93\n",
       "layer26            35.21         35.15\n",
       "layer27            35.15         35.55\n",
       "layer28            35.74         35.90\n",
       "layer29            36.21         35.88\n",
       "layer30            36.21         36.67\n",
       "layer31            36.27         36.55\n",
       "layer32            36.71         36.98\n",
       "layer33            37.00         37.44\n",
       "layer34            37.28         37.45\n",
       "layer35            37.67         37.78"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "def return_perplexity_of_sentiment_model(models_dict: Dict[str, str]):\n",
    "    res = {}\n",
    "    for model in tqdm(models_dict):\n",
    "        path_to_model = models_dict[model]\n",
    "        if path_to_model == 'None':\n",
    "            res[model] = {'ppl': -1}\n",
    "        else:\n",
    "            with open(os.path.join(path_to_model, 'eval_results_lm.txt')) as f:\n",
    "                for line in f:\n",
    "                    res[model] = {'ppl': float(line.split(' = ')[1])}\n",
    "                    break\n",
    "    return res\n",
    "\n",
    "\n",
    "POS_DIR = Path('../generations/sentiment/positive_prompts/')\n",
    "model_dir = '../models/experts/sentiment/'\n",
    "source_sentiment = 'positive'\n",
    "target_sentiment = 'negative'\n",
    "\n",
    "models = {\n",
    "    'GPT2 large': {\n",
    "        'positive_path': f'{model_dir}/large/finetuned_gpt2_train_val_sst_positive_100_maxepochs',\n",
    "        'negative_path': f'{model_dir}/large/finetuned_gpt2_train_val_sst_negative_100_maxepochs',\n",
    "    },\n",
    "    'GPT2 small': {\n",
    "        'positive_path': f'{model_dir}/small/finetuned_gpt2_train_val_sst_positive_100_maxepochs',\n",
    "        'negative_path': f'{model_dir}/small/finetuned_gpt2_train_val_sst_negative_100_maxepochs',\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in range(0, 36):\n",
    "    models[f'layer{i}'] = {\n",
    "        'positive_path': f'{model_dir}/large/finetuned_gpt2_train_val_sst_positive_experimental_freeze_emb_and_lmhead_layers{i}_100_maxepochs',\n",
    "        'negative_path': f'{model_dir}/large/finetuned_gpt2_train_val_sst_negative_experimental_freeze_emb_and_lmhead_layers{i}_100_maxepochs',\n",
    "    }\n",
    "\n",
    "positive_ppl_res = return_perplexity_of_sentiment_model({m: p['positive_path'] for m,p in models.items()})\n",
    "negative_ppl_res = return_perplexity_of_sentiment_model({m: p['negative_path'] for m,p in models.items()})\n",
    "\n",
    "negative_steering_res = {}\n",
    "for model in positive_ppl_res.keys():\n",
    "    negative_steering_res[model] = {\n",
    "        'positive_ppl': positive_ppl_res[model]['ppl'],\n",
    "        'negative_ppl': negative_ppl_res[model]['ppl'],\n",
    "    }\n",
    "    \n",
    "pd.DataFrame(negative_steering_res).transpose().round(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  5.79it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 26934.52it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 23952.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_prompts</th>\n",
       "      <th>antiexpert_ppl</th>\n",
       "      <th>expert_ppl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DExperts Small (anti-only)</th>\n",
       "      <td>90.92</td>\n",
       "      <td>42.89</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts (anti-only)</th>\n",
       "      <td>90.66</td>\n",
       "      <td>31.35</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_22 (anti-only)</th>\n",
       "      <td>86.86</td>\n",
       "      <td>34.61</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_32 (anti-only)</th>\n",
       "      <td>83.44</td>\n",
       "      <td>36.71</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_32</th>\n",
       "      <td>78.99</td>\n",
       "      <td>36.71</td>\n",
       "      <td>36.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_12 (anti-only)</th>\n",
       "      <td>77.67</td>\n",
       "      <td>34.23</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_2</th>\n",
       "      <td>69.26</td>\n",
       "      <td>33.62</td>\n",
       "      <td>32.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_2 (anti-only)</th>\n",
       "      <td>68.68</td>\n",
       "      <td>33.62</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_12</th>\n",
       "      <td>67.75</td>\n",
       "      <td>34.23</td>\n",
       "      <td>33.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_32 (expert-only)</th>\n",
       "      <td>63.69</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>36.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_22</th>\n",
       "      <td>58.88</td>\n",
       "      <td>34.61</td>\n",
       "      <td>34.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts Small</th>\n",
       "      <td>53.70</td>\n",
       "      <td>42.89</td>\n",
       "      <td>43.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_12 (expert-only)</th>\n",
       "      <td>50.54</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>33.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts (expert-only)</th>\n",
       "      <td>47.57</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>30.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts Small (expert-only)</th>\n",
       "      <td>44.15</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>43.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_2 (expert-only)</th>\n",
       "      <td>43.43</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>32.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DExperts</th>\n",
       "      <td>38.00</td>\n",
       "      <td>31.35</td>\n",
       "      <td>30.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer_22 (expert-only)</th>\n",
       "      <td>26.74</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>34.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              pos_prompts  antiexpert_ppl  expert_ppl\n",
       "DExperts Small (anti-only)          90.92           42.89       -1.00\n",
       "DExperts (anti-only)                90.66           31.35       -1.00\n",
       "Layer_22 (anti-only)                86.86           34.61       -1.00\n",
       "Layer_32 (anti-only)                83.44           36.71       -1.00\n",
       "Layer_32                            78.99           36.71       36.98\n",
       "Layer_12 (anti-only)                77.67           34.23       -1.00\n",
       "Layer_2                             69.26           33.62       32.81\n",
       "Layer_2 (anti-only)                 68.68           33.62       -1.00\n",
       "Layer_12                            67.75           34.23       33.93\n",
       "Layer_32 (expert-only)              63.69           -1.00       36.98\n",
       "Layer_22                            58.88           34.61       34.14\n",
       "DExperts Small                      53.70           42.89       43.15\n",
       "Layer_12 (expert-only)              50.54           -1.00       33.93\n",
       "DExperts (expert-only)              47.57           -1.00       30.51\n",
       "DExperts Small (expert-only)        44.15           -1.00       43.15\n",
       "Layer_2 (expert-only)               43.43           -1.00       32.81\n",
       "DExperts                            38.00           31.35       30.51\n",
       "Layer_22 (expert-only)              26.74           -1.00       34.14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### New language models train_val_sst positive\n",
    "# results corresponding to the bottom  half of Table 3\n",
    "\n",
    "model_dir = '../models/experts/sentiment/'\n",
    "POS_DIR = Path('../generations/sentiment/positive_prompts/')\n",
    "\n",
    "models = {\n",
    "    \"DExperts Small\" : {\n",
    "        'pos_path': POS_DIR / f\"small_experts/negative/dexperts/train_val_sst/prompted_gens_dexperts.jsonl\",\n",
    "        'positive_ppl_path': f'{model_dir}/small/finetuned_gpt2_train_val_sst_positive_100_maxepochs',\n",
    "        'negative_ppl_path': f'{model_dir}/small/finetuned_gpt2_train_val_sst_negative_100_maxepochs',\n",
    "    },\n",
    "    \"DExperts Small (anti-only)\" : {\n",
    "        'pos_path': POS_DIR / f\"small_experts/negative/dexperts_anti_only/train_val_sst/prompted_gens_dexperts.jsonl\",\n",
    "        'positive_ppl_path': f'{model_dir}/small/finetuned_gpt2_train_val_sst_positive_100_maxepochs',\n",
    "        'negative_ppl_path': 'None',\n",
    "    },\n",
    "    \"DExperts Small (expert-only)\" : {\n",
    "        'pos_path': POS_DIR / f\"small_experts/negative/dexperts_expert_only/train_val_sst/prompted_gens_dexperts.jsonl\",\n",
    "        'positive_ppl_path': 'None',\n",
    "        'negative_ppl_path': f'{model_dir}/small/finetuned_gpt2_train_val_sst_negative_100_maxepochs',\n",
    "    },\n",
    "    \"DExperts\" : {\n",
    "        'pos_path': POS_DIR / f\"large_experts/negative/dexperts/train_val_sst/prompted_gens_dexperts.jsonl\",\n",
    "        'positive_ppl_path': f'{model_dir}/large/finetuned_gpt2_train_val_sst_positive_100_maxepochs',\n",
    "        'negative_ppl_path': f'{model_dir}/large/finetuned_gpt2_train_val_sst_negative_100_maxepochs',\n",
    "    },\n",
    "    \"DExperts (anti-only)\" : {\n",
    "        'pos_path': POS_DIR / f\"large_experts/negative/dexperts_anti_only/train_val_sst/prompted_gens_dexperts.jsonl\",\n",
    "        'positive_ppl_path': f'{model_dir}/large/finetuned_gpt2_train_val_sst_positive_100_maxepochs',\n",
    "        'negative_ppl_path': 'None',\n",
    "    },\n",
    "    \"DExperts (expert-only)\" : {\n",
    "        'pos_path': POS_DIR / f\"large_experts/negative/dexperts_expert_only/train_val_sst/prompted_gens_dexperts.jsonl\",\n",
    "        'positive_ppl_path': 'None', \n",
    "        'negative_ppl_path': f'{model_dir}/large/finetuned_gpt2_train_val_sst_negative_100_maxepochs',\n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "for layer_num in [2, 12, 22, 32]:\n",
    "    models[f'Layer_{layer_num}'] = {\n",
    "        'pos_path': POS_DIR / f'large_experts/negative/dexperts_steer/steering_large_gpt2/alpha_3.2/layer_{layer_num}_freeze_emb_lm_head_with_expert_epochs100_train_val_sst/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'positive_ppl_path': f'{model_dir}/large/finetuned_gpt2_train_val_sst_positive_experimental_freeze_emb_and_lmhead_layers{layer_num}_100_maxepochs',\n",
    "        'negative_ppl_path': f'{model_dir}/large/finetuned_gpt2_train_val_sst_negative_experimental_freeze_emb_and_lmhead_layers{layer_num}_100_maxepochs',\n",
    "    }\n",
    "    \n",
    "    models[f'Layer_{layer_num} (anti-only)'] = {\n",
    "        'pos_path': POS_DIR / f'large_experts/negative/dexperts_steer_anti_only/steering_large_gpt2/alpha_3.2/layer_{layer_num}_freeze_emb_lm_head_epochs100_train_val_sst/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'positive_ppl_path': f'{model_dir}/large/finetuned_gpt2_train_val_sst_positive_experimental_freeze_emb_and_lmhead_layers{layer_num}_100_maxepochs',\n",
    "        'negative_ppl_path': 'None',\n",
    "    }\n",
    "    \n",
    "    models[f'Layer_{layer_num} (expert-only)'] = {\n",
    "        'pos_path': POS_DIR / f'large_experts/negative/dexperts_steer_expert_only/steering_large_gpt2/alpha_3.2/layer_{layer_num}_freeze_emb_lm_head_epochs100_train_val_sst/combine_at_layer/prompted_gens_dexperts-steer.jsonl',\n",
    "        'positive_ppl_path': 'None',\n",
    "        'negative_ppl_path': f'{model_dir}/large/finetuned_gpt2_train_val_sst_negative_experimental_freeze_emb_and_lmhead_layers{layer_num}_100_maxepochs',\n",
    "    }\n",
    "\n",
    "pos_prompts_res = read_sentiment_results({m: p['pos_path'] for m,p in models.items()})\n",
    "antiexpert_ppl_res = return_perplexity_of_sentiment_model({m: p['positive_ppl_path'] for m,p in models.items()})\n",
    "expert_ppl_res = return_perplexity_of_sentiment_model({m: p['negative_ppl_path'] for m,p in models.items()})\n",
    "negative_steering_res = {}\n",
    "#assert set(neutral_prompts_res.keys()) == set(pos_prompts_res.keys())\n",
    "for model in pos_prompts_res.keys():\n",
    "    negative_steering_res[model] = {\n",
    "        #'neutral_prompts': neutral_prompts_res[model]['positive_proportion']*100,\n",
    "        'pos_prompts': pos_prompts_res[model]['positive_proportion']*100,\n",
    "        'antiexpert_ppl': antiexpert_ppl_res[model]['ppl'],\n",
    "        'expert_ppl': expert_ppl_res[model]['ppl'],\n",
    "#         'dist-1': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-1'),\n",
    "#         'dist-2': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-2'),\n",
    "#         'dist-3': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-3'),\n",
    "#         'perplexity': weighted_average(neutral_prompts_res, pos_prompts_res, 'perplexity'),\n",
    "    }\n",
    "pd.DataFrame(negative_steering_res).transpose().sort_values(by='pos_prompts', ascending=False).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dexperts",
   "language": "python",
   "name": "dexperts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
